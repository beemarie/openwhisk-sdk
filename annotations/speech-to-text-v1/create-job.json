{
  "description": "Creates a job for an asynchronous recognition request.",
  "parameters": [
    {
      "name": "username",
      "required": false,
      "bindTime": true,
      "description": "The service username"
    },
    {
      "name": "password",
      "required": false,
      "bindTime": true,
      "description": "The service password"
    },
    {
      "name": "headers",
      "required": false,
      "bindTime": true,
      "description": "The request headers"
    },
    {
      "name": "headers[X-Watson-Learning-Opt-Out]",
      "required": false,
      "bindTime": true,
      "description": "opt-out of data collection"
    },
    {
      "name": "url",
      "required": false,
      "bindTime": true,
      "description": "override default service base url"
    },
    {
      "name": "callback_url",
      "required": false,
      "bindTime": false,
      "description":
        "A URL to which callback notifications are to be sent. The URL must already be successfully white-listed by using the `POST /v1/register_callback` method. Omit the parameter to poll the service for job completion and results. You can include the same callback URL with any number of job creation requests. Use the `user_token` query parameter to specify a unique user-specified string with each job to differentiate the callback notifications for the jobs."
    },
    {
      "name": "events",
      "required": false,
      "bindTime": false,
      "description":
        "If the job includes a callback URL, a comma-separated list of notification events to which to subscribe. Valid events are: `recognitions.started` generates a callback notification when the service begins to process the job. `recognitions.completed` generates a callback notification when the job is complete; you must use the `GET /v1/recognitions/{id}` method to retrieve the results before they time out or are deleted. `recognitions.completed_with_results` generates a callback notification when the job is complete; the notification includes the results of the request. `recognitions.failed` generates a callback notification if the service experiences an error while processing the job. Omit the parameter to subscribe to the default events: `recognitions.started`, `recognitions.completed`, and `recognitions.failed`. The `recognitions.completed` and `recognitions.completed_with_results` events are incompatible; you can specify only of the two events. If the job does not include a callback URL, omit the parameter."
    },
    {
      "name": "user_token",
      "required": false,
      "bindTime": false,
      "description":
        "If the job includes a callback URL, a user-specified string that the service is to include with each callback notification for the job; the token allows the user to maintain an internal mapping between jobs and notification events. If the job does not include a callback URL, omit the parameter."
    },
    {
      "name": "results_ttl",
      "required": false,
      "bindTime": false,
      "description":
        "The number of minutes for which the results are to be available after the job has finished. If not delivered via a callback, the results must be retrieved within this time. Omit the parameter to use a time to live of one week. The parameter is valid with or without a callback URL."
    },
    {
      "name": "transfer_encoding",
      "required": false,
      "bindTime": false,
      "description":
        "Set to `chunked` to send the audio in streaming mode. The data does not need to exist fully before being streamed to the service."
    },
    {
      "name": "audio",
      "required": true,
      "bindTime": false,
      "description":
        "Audio to transcribe in the format specified by the `Content-Type` header."
    },
    {
      "name": "content_type",
      "required": true,
      "bindTime": false,
      "description":
        "The type of the input: audio/basic, audio/flac, audio/l16, audio/mp3, audio/mpeg, audio/mulaw, audio/ogg, audio/ogg;codecs=opus, audio/ogg;codecs=vorbis, audio/wav, audio/webm, audio/webm;codecs=opus, or audio/webm;codecs=vorbis."
    },
    {
      "name": "model",
      "required": false,
      "bindTime": false,
      "description":
        "The identifier of the model to be used for the recognition request. (Use `GET /v1/models` for a list of available models.)."
    },
    {
      "name": "customization_id",
      "required": false,
      "bindTime": false,
      "description":
        "The GUID of a custom language model that is to be used with the request. The base model of the specified custom language model must match the model specified with the `model` parameter. You must make the request with service credentials created for the instance of the service that owns the custom model. By default, no custom language model is used."
    },
    {
      "name": "acoustic_customization_id",
      "required": false,
      "bindTime": false,
      "description":
        "The GUID of a custom acoustic model that is to be used with the request. The base model of the specified custom acoustic model must match the model specified with the `model` parameter. You must make the request with service credentials created for the instance of the service that owns the custom model. By default, no custom acoustic model is used."
    },
    {
      "name": "customization_weight",
      "required": false,
      "bindTime": false,
      "description":
        "If you specify a `customization_id` with the request, you can use the `customization_weight` parameter to tell the service how much weight to give to words from the custom language model compared to those from the base model for speech recognition.   Specify a value between 0.0 and 1.0. Unless a different customization weight was specified for the custom model when it was trained, the default value is 0.3. A customization weight that you specify overrides a weight that was specified when the custom model was trained.   The default value yields the best performance in general. Assign a higher value if your audio makes frequent use of OOV words from the custom model. Use caution when setting the weight: a higher value can improve the accuracy of phrases from the custom model's domain, but it can negatively affect  performance on non-domain phrases."
    },
    {
      "name": "inactivity_timeout",
      "required": false,
      "bindTime": false,
      "description":
        "The time in seconds after which, if only silence (no speech) is detected in submitted audio, the connection is closed with a 400 error. Useful for stopping audio submission from a live microphone when a user simply walks away. Use `-1` for infinity."
    },
    {
      "name": "keywords",
      "required": false,
      "bindTime": false,
      "description":
        "Array of keyword strings to spot in the audio. Each keyword string can include one or more tokens. Keywords are spotted only in the final hypothesis, not in interim results. Omit the parameter or specify an empty array if you do not need to spot keywords."
    },
    {
      "name": "keywords_threshold",
      "required": false,
      "bindTime": false,
      "description":
        "Confidence value that is the lower bound for spotting a keyword. A word is considered to match a keyword if its confidence is greater than or equal to the threshold. Specify a probability between 0 and 1 inclusive. No keyword spotting is performed if you omit the parameter. If you specify a threshold, you must also specify one or more keywords."
    },
    {
      "name": "max_alternatives",
      "required": false,
      "bindTime": false,
      "description":
        "Maximum number of alternative transcripts to be returned. By default, a single transcription is returned."
    },
    {
      "name": "word_alternatives_threshold",
      "required": false,
      "bindTime": false,
      "description":
        "Confidence value that is the lower bound for identifying a hypothesis as a possible word alternative (also known as \"Confusion Networks\"). An alternative word is considered if its confidence is greater than or equal to the threshold. Specify a probability between 0 and 1 inclusive. No alternative words are computed if you omit the parameter."
    },
    {
      "name": "word_confidence",
      "required": false,
      "bindTime": false,
      "description": "If `true`, confidence measure per word is returned."
    },
    {
      "name": "timestamps",
      "required": false,
      "bindTime": false,
      "description": "If `true`, time alignment for each word is returned."
    },
    {
      "name": "profanity_filter",
      "required": false,
      "bindTime": false,
      "description":
        "If `true` (the default), filters profanity from all output except for keyword results by replacing inappropriate words with a series of asterisks. Set the parameter to `false` to return results with no censoring. Applies to US English transcription only."
    },
    {
      "name": "smart_formatting",
      "required": false,
      "bindTime": false,
      "description":
        "If `true`, converts dates, times, series of digits and numbers, phone numbers, currency values, and Internet addresses into more readable, conventional representations in the final transcript of a recognition request. If `false` (the default), no formatting is performed. Applies to US English transcription only."
    },
    {
      "name": "speaker_labels",
      "required": false,
      "bindTime": false,
      "description":
        "Indicates whether labels that identify which words were spoken by which participants in a multi-person exchange are to be included in the response. The default is `false`; no speaker labels are returned. Setting `speaker_labels` to `true` forces the `timestamps` parameter to be `true`, regardless of whether you specify `false` for the parameter.   To determine whether a language model supports speaker labels, use the `GET /v1/models` method and check that the attribute `speaker_labels` is set to `true`. You can also refer to [Speaker labels](https://console.bluemix.net/docs/services/speech-to-text/output.html#speaker_labels)."
    }
  ],
  "sampleInput": "Coming soon!",
  "sampleOutput": "Coming soon!"
}
